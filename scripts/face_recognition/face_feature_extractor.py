import os
import cv2
import numpy as np
import insightface
import requests
import json
import base64
from pathlib import Path
import logging
from typing import List, Dict, Optional, Tuple
import time
import asyncio
import aiohttp
from sklearn.preprocessing import normalize
import argparse
import json
import sys

# C·∫•u h√¨nh logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class FaceFeatureExtractor:
    def __init__(self, backend_api_url: str, face_api_url: str, project_root: str, credentials: Dict = None):
        """
        Kh·ªüi t·∫°o class tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng khu√¥n m·∫∑t

        Args:
            backend_api_url: URL c·ªßa Spring Boot backend API
            face_api_url: URL c·ªßa Face Recognition service API
            project_root: ƒê∆∞·ªùng d·∫´n g·ªëc project face-attendance
            credentials: Dict v·ªõi username/password ƒë·ªÉ ƒëƒÉng nh·∫≠p (optional)
        """
        self.backend_api_url = backend_api_url.rstrip('/')
        self.face_api_url = face_api_url.rstrip('/')
        self.credentials = credentials
        self.session_cookies = None  # L∆∞u cookies sau khi ƒëƒÉng nh·∫≠p

        # ƒê∆∞·ªùng d·∫´n ch√≠nh x√°c theo c·∫•u tr√∫c project
        self.project_root = Path(project_root)
        self.student_base_dir = self.project_root / "src" / "main" / "resources" / "static" / "uploads" / "students"

        # Initialize InsightFace model
        self.app = insightface.app.FaceAnalysis(
            providers=['CPUExecutionProvider'],  # Ho·∫∑c 'CUDAExecutionProvider' n·∫øu c√≥ GPU
            name='buffalo_l'  # Model ch·∫•t l∆∞·ª£ng cao nh∆∞ backend
        )
        self.app.prepare(ctx_id=0, det_size=(640, 640))

        self.headers = {
            'Content-Type': 'application/json',
            'Accept': 'application/json'
        }

        # C·∫•u h√¨nh theo backend settings
        self.detection_threshold = 0.5
        self.recognition_threshold = 0.6
        self.max_face_size = 1920
        self.min_face_size = 40
        self.required_face_images = 5  # 5 ·∫£nh faces + 1 profile

        logger.info(f"FaceFeatureExtractor initialized")
        logger.info(f"Project root: {self.project_root}")
        logger.info(f"Student base directory: {self.student_base_dir}")

        # N·∫øu c√≥ credentials, s·∫Ω ƒëƒÉng nh·∫≠p khi c·∫ßn
        if credentials:
            logger.info(f"Authentication credentials provided for user: {credentials.get('username')}")

    async def login_session(self) -> bool:
        """
        ƒêƒÉng nh·∫≠p ƒë·ªÉ l·∫•y session cookies

        Returns:
            True n·∫øu ƒëƒÉng nh·∫≠p th√†nh c√¥ng
        """
        if not self.credentials:
            logger.warning("No credentials provided for authentication")
            return False

        try:
            login_data = {
                'username': self.credentials['username'],
                'password': self.credentials['password']
            }

            async with aiohttp.ClientSession() as session:
                url = f"{self.backend_api_url}/auth/login"
                async with session.post(url, json=login_data, headers=self.headers) as response:
                    if response.status == 200:
                        # L∆∞u cookies t·ª´ response
                        self.session_cookies = response.cookies
                        logger.info("‚úÖ Login successful, session established")
                        return True
                    else:
                        response_text = await response.text()
                        logger.error(f"‚ùå Login failed: {response.status} - {response_text}")
                        return False

        except Exception as e:
            logger.error(f"Login error: {str(e)}")
            return False

    def get_student_image_paths(self, ma_sv: str) -> Dict:
        """
        L·∫•y ƒë∆∞·ªùng d·∫´n ·∫£nh c·ªßa sinh vi√™n theo c·∫•u tr√∫c th·ª±c t·∫ø

        Args:
            ma_sv: M√£ sinh vi√™n

        Returns:
            Dictionary ch·ª©a ƒë∆∞·ªùng d·∫´n c√°c ·∫£nh
        """
        student_dir = self.student_base_dir / ma_sv
        faces_dir = student_dir / "faces"

        result = {
            'student_dir': student_dir,
            'profile_image': None,
            'face_images': [],
            'exists': student_dir.exists()
        }

        if not student_dir.exists():
            logger.warning(f"Th∆∞ m·ª•c sinh vi√™n kh√¥ng t·ªìn t·∫°i: {student_dir}")
            return result

        # T√¨m ·∫£nh profile
        for ext in ['.jpg', '.jpeg', '.png', '.webp']:
            profile_path = student_dir / f"profile{ext}"
            if profile_path.exists():
                result['profile_image'] = profile_path
                break

        # T√¨m ·∫£nh faces
        if faces_dir.exists():
            for i in range(1, 6):  # face_1.jpg ƒë·∫øn face_5.jpg
                for ext in ['.jpg', '.jpeg', '.png', '.webp']:
                    face_path = faces_dir / f"face_{i}{ext}"
                    if face_path.exists():
                        result['face_images'].append(face_path)
                        break

        logger.info(f"Sinh vi√™n {ma_sv}: Profile={'‚úì' if result['profile_image'] else '‚úó'}, "
                    f"Faces={len(result['face_images'])}/5")

        return result

    def load_and_preprocess_image(self, image_path: Path) -> Optional[np.ndarray]:
        """
        Load v√† ti·ªÅn x·ª≠ l√Ω ·∫£nh theo chu·∫©n InsightFace

        Args:
            image_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn ·∫£nh

        Returns:
            ·∫¢nh ƒë√£ ƒë∆∞·ª£c ti·ªÅn x·ª≠ l√Ω ho·∫∑c None n·∫øu l·ªói
        """
        try:
            # ƒê·ªçc ·∫£nh
            image = cv2.imread(str(image_path))
            if image is None:
                logger.warning(f"Kh√¥ng th·ªÉ ƒë·ªçc ·∫£nh: {image_path}")
                return None

            # Resize n·∫øu ·∫£nh qu√° l·ªõn
            height, width = image.shape[:2]
            if width > self.max_face_size or height > self.max_face_size:
                scale = self.max_face_size / max(width, height)
                new_width = int(width * scale)
                new_height = int(height * scale)
                image = cv2.resize(image, (new_width, new_height))

            return image
        except Exception as e:
            logger.error(f"L·ªói khi x·ª≠ l√Ω ·∫£nh {image_path}: {str(e)}")
            return None

    def extract_face_features(self, image_paths: List[Path]) -> Tuple[List[np.ndarray], Dict]:
        """
        Tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng khu√¥n m·∫∑t s·ª≠ d·ª•ng InsightFace

        Args:
            image_paths: Danh s√°ch ƒë∆∞·ªùng d·∫´n ·∫£nh

        Returns:
            Tuple c·ªßa (danh s√°ch embeddings, metadata)
        """
        all_embeddings = []
        face_metadata = {
            'total_images': len(image_paths),
            'processed_images': 0,
            'valid_faces': 0,
            'face_qualities': [],
            'detection_results': []
        }

        for i, image_path in enumerate(image_paths):
            image = self.load_and_preprocess_image(image_path)
            if image is None:
                face_metadata['detection_results'].append({
                    'image': image_path.name,
                    'status': 'failed_to_load'
                })
                continue

            try:
                # Detect faces using InsightFace
                faces = self.app.get(image)

                if not faces:
                    logger.warning(f"Kh√¥ng t√¨m th·∫•y khu√¥n m·∫∑t trong ·∫£nh: {image_path.name}")
                    face_metadata['detection_results'].append({
                        'image': image_path.name,
                        'status': 'no_face_detected'
                    })
                    continue

                # Ch·ªçn khu√¥n m·∫∑t t·ªët nh·∫•t (det_score cao nh·∫•t v√† k√≠ch th∆∞·ªõc l·ªõn nh·∫•t)
                best_face = max(faces, key=lambda x: x.det_score * self._calculate_face_area(x.bbox))

                # Ki·ªÉm tra ch·∫•t l∆∞·ª£ng khu√¥n m·∫∑t
                face_area = self._calculate_face_area(best_face.bbox)
                if face_area < self.min_face_size * self.min_face_size:
                    logger.warning(f"Khu√¥n m·∫∑t qu√° nh·ªè trong ·∫£nh: {image_path.name}")
                    face_metadata['detection_results'].append({
                        'image': image_path.name,
                        'status': 'face_too_small',
                        'area': face_area
                    })
                    continue

                # Tr√≠ch xu·∫•t embedding
                embedding = best_face.normed_embedding

                # Validate embedding
                if embedding is None or len(embedding) != 512:
                    logger.warning(f"Embedding kh√¥ng h·ª£p l·ªá cho ·∫£nh: {image_path.name}")
                    continue

                all_embeddings.append(embedding)
                face_metadata['valid_faces'] += 1
                face_metadata['face_qualities'].append({
                    'image': image_path.name,
                    'det_score': float(best_face.det_score),
                    'face_area': face_area,
                    'age': int(best_face.age) if hasattr(best_face, 'age') else None,
                    'gender': int(best_face.gender) if hasattr(best_face, 'gender') else None
                })
                face_metadata['detection_results'].append({
                    'image': image_path.name,
                    'status': 'success',
                    'det_score': float(best_face.det_score),
                    'face_area': face_area
                })

                logger.info(f"Tr√≠ch xu·∫•t th√†nh c√¥ng t·ª´: {image_path.name} (score: {best_face.det_score:.3f})")

            except Exception as e:
                logger.error(f"L·ªói khi tr√≠ch xu·∫•t t·ª´ {image_path.name}: {str(e)}")
                face_metadata['detection_results'].append({
                    'image': image_path.name,
                    'status': 'extraction_error',
                    'error': str(e)
                })
                continue

            face_metadata['processed_images'] += 1

        return all_embeddings, face_metadata

    def _calculate_face_area(self, bbox) -> float:
        """T√≠nh di·ªán t√≠ch khu√¥n m·∫∑t t·ª´ bounding box"""
        return (bbox[2] - bbox[0]) * (bbox[3] - bbox[1])

    def create_composite_embedding(self, embeddings: List[np.ndarray], method: str = "mean") -> Optional[np.ndarray]:
        """
        T·∫°o embedding t·ªïng h·ª£p t·ª´ nhi·ªÅu embeddings theo backend logic

        Args:
            embeddings: Danh s√°ch c√°c embedding vectors
            method: Ph∆∞∆°ng ph√°p t·ªïng h·ª£p ("mean", "median", "weighted_mean")

        Returns:
            Embedding t·ªïng h·ª£p ƒë√£ ƒë∆∞·ª£c normalize
        """
        if not embeddings:
            return None

        embeddings_array = np.array(embeddings)

        if method == "mean":
            composite = np.mean(embeddings_array, axis=0)
        elif method == "median":
            composite = np.median(embeddings_array, axis=0)
        elif method == "weighted_mean":
            # Weight by quality scores if available
            composite = np.mean(embeddings_array, axis=0)
        else:
            composite = np.mean(embeddings_array, axis=0)

        # Normalize embedding nh∆∞ backend
        composite_normalized = normalize([composite], norm='l2')[0]

        return composite_normalized

    def validate_embeddings_quality(self, embeddings: List[np.ndarray]) -> Dict:
        """
        Ki·ªÉm tra ch·∫•t l∆∞·ª£ng c·ªßa c√°c embeddings

        Args:
            embeddings: Danh s√°ch c√°c embedding vectors

        Returns:
            Dictionary ch·ª©a th√¥ng tin v·ªÅ ch·∫•t l∆∞·ª£ng
        """
        if len(embeddings) < 2:
            return {
                'is_valid': len(embeddings) >= 1,
                'num_embeddings': len(embeddings),
                'avg_similarity': None,
                'min_similarity': None,
                'max_similarity': None,
                'std_similarity': None,
                'recommendation': 'C·∫ßn √≠t nh·∫•t 2 ·∫£nh ƒë·ªÉ ƒë√°nh gi√° ch·∫•t l∆∞·ª£ng'
            }

        # T√≠nh cosine similarity gi·ªØa c√°c embeddings
        similarities = []
        for i in range(len(embeddings)):
            for j in range(i + 1, len(embeddings)):
                similarity = np.dot(embeddings[i], embeddings[j])
                similarities.append(similarity)

        similarities = np.array(similarities)
        avg_similarity = np.mean(similarities)

        # ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng
        is_good_quality = avg_similarity > self.recognition_threshold and len(embeddings) >= 3

        quality_info = {
            'is_valid': avg_similarity > 0.4,  # Threshold th·∫•p h∆°n ƒë·ªÉ accept
            'is_good_quality': is_good_quality,
            'num_embeddings': len(embeddings),
            'avg_similarity': float(avg_similarity),
            'min_similarity': float(np.min(similarities)),
            'max_similarity': float(np.max(similarities)),
            'std_similarity': float(np.std(similarities)),
            'recommendation': self._get_quality_recommendation(avg_similarity, len(embeddings))
        }

        logger.info(f"Ch·∫•t l∆∞·ª£ng embeddings: Similarity={avg_similarity:.3f}, Count={len(embeddings)}")
        return quality_info

    def _get_quality_recommendation(self, avg_similarity: float, num_embeddings: int) -> str:
        """ƒê∆∞a ra khuy·∫øn ngh·ªã v·ªÅ ch·∫•t l∆∞·ª£ng"""
        if avg_similarity > 0.8 and num_embeddings >= 4:
            return "Ch·∫•t l∆∞·ª£ng tuy·ªát v·ªùi"
        elif avg_similarity > 0.6 and num_embeddings >= 3:
            return "Ch·∫•t l∆∞·ª£ng t·ªët"
        elif avg_similarity > 0.4:
            return "Ch·∫•t l∆∞·ª£ng kh√°, n√™n th√™m ·∫£nh ho·∫∑c ch·ª•p l·∫°i"
        else:
            return "Ch·∫•t l∆∞·ª£ng k√©m, c·∫ßn ch·ª•p l·∫°i t·∫•t c·∫£ ·∫£nh"

    async def get_student_info(self, ma_sv: str) -> Optional[Dict]:
        """
        L·∫•y th√¥ng tin sinh vi√™n t·ª´ backend - Th·ª≠ nhi·ªÅu c√°ch

        Args:
            ma_sv: M√£ sinh vi√™n

        Returns:
            Th√¥ng tin sinh vi√™n ho·∫∑c None
        """
        # C√°ch 1: Th·ª≠ l·∫•y qua endpoint th√¥ng th∆∞·ªùng (c√≥ th·ªÉ b·ªã auth)
        try:
            async with aiohttp.ClientSession() as session:
                url = f"{self.backend_api_url}/sinhvien/by-masv/{ma_sv}"
                async with session.get(url, headers=self.headers) as response:
                    if response.status == 200:
                        data = await response.json()
                        logger.info(f"‚úì [Normal API] Sinh vi√™n {ma_sv} t·ªìn t·∫°i: {data.get('hoTen', 'N/A')}")
                        return data
        except Exception as e:
            logger.debug(f"Normal API failed for {ma_sv}: {e}")

        # C√°ch 2: Th·ª≠ v·ªõi authentication n·∫øu c√≥
        if self.credentials:
            # ƒêƒÉng nh·∫≠p n·∫øu ch∆∞a c√≥ session
            if not self.session_cookies:
                await self.login_session()

            if self.session_cookies:
                try:
                    async with aiohttp.ClientSession(cookies=self.session_cookies) as session:
                        url = f"{self.backend_api_url}/sinhvien/by-masv/{ma_sv}"
                        async with session.get(url, headers=self.headers) as response:
                            if response.status == 200:
                                data = await response.json()
                                logger.info(f"‚úì [Auth API] Sinh vi√™n {ma_sv} t·ªìn t·∫°i: {data.get('hoTen', 'N/A')}")
                                return data
                except Exception as e:
                    logger.debug(f"Authenticated API failed for {ma_sv}: {e}")

        # C√°ch 3: Ki·ªÉm tra th∆∞ m·ª•c file t·ªìn t·∫°i (fallback logic)
        student_dir = self.student_base_dir / ma_sv
        if student_dir.exists():
            logger.warning(f"‚ö†Ô∏è  Kh√¥ng th·ªÉ verify sinh vi√™n {ma_sv} qua API, nh∆∞ng th∆∞ m·ª•c t·ªìn t·∫°i")
            return {
                'maSv': ma_sv,
                'hoTen': f'Student_{ma_sv}',
                'note': 'Directory exists, API verification failed'
            }
        else:
            logger.error(f"‚ùå Sinh vi√™n {ma_sv} kh√¥ng t·ªìn t·∫°i (kh√¥ng c√≥ th∆∞ m·ª•c)")
            return None

    async def save_embedding_to_backend(self, ma_sv: str, embedding: np.ndarray) -> bool:
        """
        L∆∞u embedding v√†o backend database - S·ª≠ d·ª•ng Python API

        Args:
            ma_sv: M√£ sinh vi√™n
            embedding: Embedding vector

        Returns:
            True n·∫øu l∆∞u th√†nh c√¥ng
        """
        # Chuy·ªÉn embedding th√†nh base64 string nh∆∞ backend expect
        embedding_bytes = embedding.astype(np.float32).tobytes()
        embedding_b64 = base64.b64encode(embedding_bytes).decode('utf-8')

        payload = {
            'embedding': embedding_b64
        }

        # C√°ch 1: Th·ª≠ Python API endpoint (kh√¥ng c·∫ßn auth) - ƒê√öNG ENDPOINT
        try:
            async with aiohttp.ClientSession() as session:
                url = f"{self.backend_api_url}/python/students/{ma_sv}/embedding"
                async with session.post(url, json=payload, headers=self.headers) as response:
                    if response.status == 200:
                        logger.info(f"‚úì [Python API] L∆∞u embedding cho sinh vi√™n {ma_sv} th√†nh c√¥ng")
                        return True
                    else:
                        response_text = await response.text()
                        logger.debug(f"Python API save failed for {ma_sv}: {response.status} - {response_text}")
        except Exception as e:
            logger.debug(f"Python API save failed for {ma_sv}: {e}")

        # C√°ch 2: Th·ª≠ v·ªõi authentication
        if self.credentials:
            # ƒêƒÉng nh·∫≠p n·∫øu ch∆∞a c√≥ session
            if not self.session_cookies:
                await self.login_session()

            if self.session_cookies:
                try:
                    async with aiohttp.ClientSession(cookies=self.session_cookies) as session:
                        url = f"{self.backend_api_url}/sinhvien/students/{ma_sv}/embedding"
                        async with session.post(url, json=payload, headers=self.headers) as response:
                            if response.status == 200:
                                logger.info(f"‚úì [Auth API] L∆∞u embedding cho sinh vi√™n {ma_sv} th√†nh c√¥ng")
                                return True
                            else:
                                response_text = await response.text()
                                logger.error(f"‚úó Auth API save failed for {ma_sv}: {response.status} - {response_text}")
                except Exception as e:
                    logger.debug(f"Authenticated API save failed for {ma_sv}: {e}")

        # C√°ch 3: L∆∞u file local (fallback)
        try:
            embeddings_dir = self.project_root / "data" / "embeddings"
            embeddings_dir.mkdir(parents=True, exist_ok=True)

            embedding_file = embeddings_dir / f"{ma_sv}.npy"
            np.save(embedding_file, embedding)

            # L∆∞u th√™m metadata
            metadata_file = embeddings_dir / f"{ma_sv}_metadata.json"
            metadata = {
                'ma_sv': ma_sv,
                'embedding_shape': embedding.shape,
                'embedding_norm': float(np.linalg.norm(embedding)),
                'timestamp': time.time(),
                'note': 'Saved locally due to API failure'
            }
            with open(metadata_file, 'w') as f:
                json.dump(metadata, f, indent=2)

            logger.warning(f"‚ö†Ô∏è  L∆∞u embedding local cho {ma_sv}: {embedding_file}")
            return True
        except Exception as e:
            logger.error(f"‚ùå Kh√¥ng th·ªÉ l∆∞u embedding cho {ma_sv}: {e}")
            return False

    async def trigger_feature_extraction(self, ma_sv: str) -> bool:
        """
        Trigger feature extraction qua Face Recognition Service ƒë·ªÉ c·∫≠p nh·∫≠t cache

        Args:
            ma_sv: M√£ sinh vi√™n

        Returns:
            True n·∫øu trigger th√†nh c√¥ng
        """
        try:
            async with aiohttp.ClientSession() as session:
                url = f"{self.face_api_url}/api/v1/features/extract/{ma_sv}"
                async with session.post(url, headers=self.headers) as response:
                    if response.status == 200:
                        data = await response.json()
                        logger.info(f"‚úì Trigger extraction cho {ma_sv}: {data.get('message')}")
                        return True
                    else:
                        response_text = await response.text()
                        logger.warning(f"Trigger extraction cho {ma_sv} failed: {response.status}")
                        return False

        except Exception as e:
            logger.warning(f"Kh√¥ng th·ªÉ trigger extraction cho {ma_sv}: {str(e)}")
            return False

    async def process_student(self, ma_sv: str) -> Dict:
        """
        X·ª≠ l√Ω m·ªôt sinh vi√™n c·ª• th·ªÉ

        Args:
            ma_sv: M√£ sinh vi√™n

        Returns:
            K·∫øt qu·∫£ x·ª≠ l√Ω chi ti·∫øt
        """
        logger.info(f"üîÑ B·∫Øt ƒë·∫ßu x·ª≠ l√Ω sinh vi√™n: {ma_sv}")

        result = {
            'ma_sv': ma_sv,
            'status': 'failed',
            'message': '',
            'metadata': {}
        }

        # 1. Ki·ªÉm tra sinh vi√™n c√≥ t·ªìn t·∫°i trong database
        student_info = await self.get_student_info(ma_sv)
        if not student_info:
            result['message'] = f"Sinh vi√™n {ma_sv} kh√¥ng t·ªìn t·∫°i trong database"
            return result

        # 2. L·∫•y ƒë∆∞·ªùng d·∫´n ·∫£nh
        image_paths = self.get_student_image_paths(ma_sv)
        if not image_paths['exists']:
            result['message'] = f"Th∆∞ m·ª•c sinh vi√™n {ma_sv} kh√¥ng t·ªìn t·∫°i"
            return result

        # 3. Collect t·∫•t c·∫£ ·∫£nh c√≥ s·∫µn
        all_images = []
        if image_paths['profile_image']:
            all_images.append(image_paths['profile_image'])
        all_images.extend(image_paths['face_images'])

        if len(all_images) == 0:
            result['message'] = f"Kh√¥ng t√¨m th·∫•y ·∫£nh n√†o cho sinh vi√™n {ma_sv}"
            return result

        logger.info(f"üì∏ T√¨m th·∫•y {len(all_images)} ·∫£nh cho sinh vi√™n {ma_sv}")

        # 4. Tr√≠ch xu·∫•t features
        embeddings, face_metadata = self.extract_face_features(all_images)

        if not embeddings:
            result['message'] = f"Kh√¥ng tr√≠ch xu·∫•t ƒë∆∞·ª£c embedding n√†o cho sinh vi√™n {ma_sv}"
            result['metadata'] = {'face_metadata': face_metadata}
            return result

        # 5. Ki·ªÉm tra ch·∫•t l∆∞·ª£ng
        quality_info = self.validate_embeddings_quality(embeddings)

        # 6. T·∫°o composite embedding
        composite_embedding = self.create_composite_embedding(embeddings, method="mean")

        if composite_embedding is None:
            result['message'] = f"Kh√¥ng th·ªÉ t·∫°o composite embedding cho sinh vi√™n {ma_sv}"
            return result

        # 7. L∆∞u embedding v√†o database
        save_success = await self.save_embedding_to_backend(ma_sv, composite_embedding)

        if save_success:
            # 8. Trigger feature extraction service ƒë·ªÉ c·∫≠p nh·∫≠t cache
            await self.trigger_feature_extraction(ma_sv)

            result['status'] = 'success'
            result['message'] = f"‚úÖ X·ª≠ l√Ω th√†nh c√¥ng sinh vi√™n {ma_sv} ({quality_info['recommendation']})"
            result['metadata'] = {
                'student_info': {
                    'ho_ten': student_info.get('hoTen', 'N/A'),
                    'ma_lop': student_info.get('maLop', 'N/A')
                },
                'images': {
                    'total_found': len(all_images),
                    'profile_available': image_paths['profile_image'] is not None,
                    'face_images_count': len(image_paths['face_images'])
                },
                'face_metadata': face_metadata,
                'quality_info': quality_info,
                'embedding_info': {
                    'dimension': len(composite_embedding),
                    'norm': float(np.linalg.norm(composite_embedding))
                }
            }
        else:
            result['message'] = f"‚ùå L·ªói l∆∞u embedding cho sinh vi√™n {ma_sv}"
            result['metadata'] = {
                'face_metadata': face_metadata,
                'quality_info': quality_info
            }

        return result

    async def process_all_students(self) -> Dict:
        """
        T·ª± ƒë·ªông t√¨m v√† x·ª≠ l√Ω t·∫•t c·∫£ sinh vi√™n c√≥ trong th∆∞ m·ª•c uploads

        Returns:
            K·∫øt qu·∫£ x·ª≠ l√Ω t·ªïng h·ª£p
        """
        logger.info(f"üîç T√¨m ki·∫øm sinh vi√™n trong: {self.student_base_dir}")

        if not self.student_base_dir.exists():
            logger.error(f"Th∆∞ m·ª•c sinh vi√™n kh√¥ng t·ªìn t·∫°i: {self.student_base_dir}")
            return {
                'success': False,
                'error': 'Student base directory not found',
                'results': {}
            }

        # T√¨m t·∫•t c·∫£ th∆∞ m·ª•c sinh vi√™n
        student_folders = [
            folder.name for folder in self.student_base_dir.iterdir()
            if folder.is_dir() and not folder.name.startswith('.')
        ]

        if not student_folders:
            logger.warning("Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c sinh vi√™n n√†o")
            return {
                'success': True,
                'total_students': 0,
                'results': {}
            }

        logger.info(f"üìÇ T√¨m th·∫•y {len(student_folders)} th∆∞ m·ª•c sinh vi√™n")

        results = {}
        success_count = 0

        # X·ª≠ l√Ω t·ª´ng sinh vi√™n
        for ma_sv in student_folders:
            try:
                result = await self.process_student(ma_sv)
                results[ma_sv] = result

                if result['status'] == 'success':
                    success_count += 1

            except Exception as e:
                logger.error(f"‚ùå L·ªói khi x·ª≠ l√Ω sinh vi√™n {ma_sv}: {str(e)}")
                results[ma_sv] = {
                    'ma_sv': ma_sv,
                    'status': 'error',
                    'message': f"Exception: {str(e)}",
                    'metadata': {}
                }

        # T·∫°o b√°o c√°o t·ªïng h·ª£p
        summary = {
            'success': True,
            'total_students': len(student_folders),
            'success_count': success_count,
            'failed_count': len(student_folders) - success_count,
            'success_rate': success_count / len(student_folders) * 100 if student_folders else 0,
            'results': results
        }

        logger.info(
            f"üèÅ Ho√†n th√†nh x·ª≠ l√Ω. Th√†nh c√¥ng: {success_count}/{len(student_folders)} ({summary['success_rate']:.1f}%)")
        return summary


def print_detailed_results(results: Dict):
    """In k·∫øt qu·∫£ chi ti·∫øt v√† ƒë·∫πp m·∫Øt"""
    print("\n" + "=" * 100)
    print("üìä B√ÅO C√ÅO TR√çCH XU·∫§T ƒê·∫∂C TR∆ØNG KHU√îN M·∫∂T SINH VI√äN")
    print("=" * 100)

    print(f"üìà T·ªîNG QUAN:")
    print(f"   ‚Ä¢ T·ªïng s·ªë sinh vi√™n: {results['total_students']}")
    print(f"   ‚Ä¢ Th√†nh c√¥ng: {results['success_count']} ‚úÖ")
    print(f"   ‚Ä¢ Th·∫•t b·∫°i: {results['failed_count']} ‚ùå")
    print(f"   ‚Ä¢ T·ª∑ l·ªá th√†nh c√¥ng: {results['success_rate']:.1f}%")

    print(f"\nüìã CHI TI·∫æT T·ª™NG SINH VI√äN:")
    print("-" * 100)

    # Nh√≥m k·∫øt qu·∫£ theo tr·∫°ng th√°i
    success_students = []
    failed_students = []
    error_students = []

    for ma_sv, result in results['results'].items():
        if result['status'] == 'success':
            success_students.append((ma_sv, result))
        elif result['status'] == 'failed':
            failed_students.append((ma_sv, result))
        else:
            error_students.append((ma_sv, result))

    # In sinh vi√™n th√†nh c√¥ng
    if success_students:
        print(f"\n‚úÖ SINH VI√äN X·ª¨ L√ù TH√ÄNH C√îNG ({len(success_students)}):")
        for ma_sv, result in success_students:
            metadata = result.get('metadata', {})
            student_info = metadata.get('student_info', {})
            images_info = metadata.get('images', {})
            quality_info = metadata.get('quality_info', {})

            print(f"   üéì {ma_sv} - {student_info.get('ho_ten', 'N/A')}")
            print(
                f"      üì∏ ·∫¢nh: {images_info.get('total_found', 0)} (Profile: {'‚úì' if images_info.get('profile_available') else '‚úó'}, Faces: {images_info.get('face_images_count', 0)})")
            if quality_info.get('avg_similarity'):
                print(
                    f"      üéØ Ch·∫•t l∆∞·ª£ng: {quality_info['avg_similarity']:.3f} ({quality_info.get('recommendation', 'N/A')})")

    # In sinh vi√™n th·∫•t b·∫°i
    if failed_students:
        print(f"\n‚ùå SINH VI√äN X·ª¨ L√ù TH·∫§T B·∫†I ({len(failed_students)}):")
        for ma_sv, result in failed_students:
            print(f"   ‚ö†Ô∏è  {ma_sv}: {result['message']}")

    # In sinh vi√™n l·ªói
    if error_students:
        print(f"\nüö´ SINH VI√äN G·∫∂P L·ªñI ({len(error_students)}):")
        for ma_sv, result in error_students:
            print(f"   üí• {ma_sv}: {result['message']}")

    print("\n" + "=" * 100)

async def process_single_student(ma_sv: str, extractor: 'FaceFeatureExtractor') -> None:
    """
    X·ª≠ l√Ω m·ªôt sinh vi√™n duy nh·∫•t v√† tr·∫£ v·ªÅ k·∫øt qu·∫£ d∆∞·ªõi d·∫°ng JSON

    Args:
        ma_sv: M√£ sinh vi√™n
        extractor: Instance c·ªßa FaceFeatureExtractor
    """
    try:
        logger.info(f"üîÑ Processing single student: {ma_sv}")

        # X·ª≠ l√Ω sinh vi√™n
        result = await extractor.process_student(ma_sv)

        # Chu·∫©n b·ªã k·∫øt qu·∫£ JSON
        json_result = {
            "success": result['status'] == 'success',
            "student_id": ma_sv,
            "status": result['status'],
            "message": result['message'],
            "embedding": result.get('embedding'),
            "metadata": result.get('metadata', {})
        }

        # In JSON result ƒë·ªÉ Java c√≥ th·ªÉ parse
        print(json.dumps(json_result, ensure_ascii=False, indent=2))

        # Exit code
        sys.exit(0 if result['status'] == 'success' else 1)

    except Exception as e:
        logger.error(f"üí• Error processing single student {ma_sv}: {str(e)}")

        # In JSON error result
        error_result = {
            "success": False,
            "student_id": ma_sv,
            "status": "error",
            "message": f"L·ªói x·ª≠ l√Ω sinh vi√™n: {str(e)}",
            "error": str(e)
        }

        print(json.dumps(error_result, ensure_ascii=False, indent=2))
        sys.exit(1)

def parse_arguments():
    """Parse command line arguments"""
    parser = argparse.ArgumentParser(description='Face Feature Extractor')

    # Mode selection
    parser.add_argument('--single-student', action='store_true',
                        help='Process single student mode')
    parser.add_argument('--batch-mode', action='store_true',
                        help='Process all students mode')

    # Student ID for single mode
    parser.add_argument('--student-id', type=str,
                        help='Student ID for single student mode')

    # Configuration overrides
    parser.add_argument('--project-root', type=str,
                        help='Override project root path')
    parser.add_argument('--backend-api', type=str,
                        help='Override backend API URL')
    parser.add_argument('--face-api', type=str,
                        help='Override face API URL')

    return parser.parse_args()

async def main():
    """
    Enhanced main function v·ªõi argument parsing
    """
    args = parse_arguments()

    # ========== C·∫§U H√åNH H·ªÜ TH·ªêNG ==========
    PROJECT_ROOT = args.project_root or "/home/loki/Desktop/face-attendance"
    BACKEND_API_URL = args.backend_api or "http://localhost:8080/api"
    FACE_API_URL = args.face_api or "http://localhost:8001"

    # ========== C·∫§U H√åNH X√ÅC TH·ª∞C ==========
    CREDENTIALS = {
        'username': 'admin',
        'password': 'admin123'
    }

    # Kh·ªüi t·∫°o extractor
    extractor = FaceFeatureExtractor(BACKEND_API_URL, FACE_API_URL, PROJECT_ROOT, CREDENTIALS)

    # Ki·ªÉm tra th∆∞ m·ª•c t·ªìn t·∫°i
    if not extractor.student_base_dir.exists():
        if args.single_student:
            error_result = {
                "success": False,
                "status": "error",
                "message": f"Th∆∞ m·ª•c sinh vi√™n kh√¥ng t·ªìn t·∫°i: {extractor.student_base_dir}"
            }
            print(json.dumps(error_result, ensure_ascii=False, indent=2))
            sys.exit(1)
        else:
            print(f"‚ùå L·ªói: Th∆∞ m·ª•c sinh vi√™n kh√¥ng t·ªìn t·∫°i: {extractor.student_base_dir}")
            return

    # X·ª≠ l√Ω theo mode
    if args.single_student:
        # Single student mode
        if not args.student_id:
            error_result = {
                "success": False,
                "status": "error",
                "message": "C·∫ßn cung c·∫•p --student-id cho single student mode"
            }
            print(json.dumps(error_result, ensure_ascii=False, indent=2))
            sys.exit(1)

        # Test k·∫øt n·ªëi API (optional)
        if CREDENTIALS:
            login_success = await extractor.login_session()
            if not login_success:
                logger.warning("‚ö†Ô∏è ƒêƒÉng nh·∫≠p API th·∫•t b·∫°i, s·∫Ω th·ª≠ fallback methods")

        # X·ª≠ l√Ω sinh vi√™n duy nh·∫•t
        await process_single_student(args.student_id, extractor)

    elif args.batch_mode:
        # Batch mode (existing logic)
        print("üöÄ KH·ªûI ƒê·ªòNG SCRIPT TR√çCH XU·∫§T ƒê·∫∂C TR∆ØNG KHU√îN M·∫∂T - BATCH MODE")
        print("=" * 60)
        print(f"üìÅ Project root: {PROJECT_ROOT}")
        print(f"üîó Backend API: {BACKEND_API_URL}")
        print(f"ü§ñ Face API: {FACE_API_URL}")

        # Test k·∫øt n·ªëi API
        if CREDENTIALS:
            print("üîÑ Ki·ªÉm tra k·∫øt n·ªëi API...")
            login_success = await extractor.login_session()
            if login_success:
                print("‚úÖ K·∫øt n·ªëi API th√†nh c√¥ng")
            else:
                print("‚ö†Ô∏è ƒêƒÉng nh·∫≠p API th·∫•t b·∫°i, s·∫Ω th·ª≠ fallback methods")

        # X·ª≠ l√Ω t·∫•t c·∫£ sinh vi√™n
        logger.info("üîÑ B·∫Øt ƒë·∫ßu x·ª≠ l√Ω batch tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng...")
        results = await extractor.process_all_students()

        # In k·∫øt qu·∫£ chi ti·∫øt
        print_detailed_results(results)

        # L∆∞u k·∫øt qu·∫£ ra file
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        report_file = f"face_extraction_report_{timestamp}.json"

        try:
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2, default=str)
            print(f"üíæ B√°o c√°o ƒë√£ ƒë∆∞·ª£c l∆∞u: {report_file}")

            # In JSON result cho batch mode
            batch_result = {
                "success": True,
                "batch_mode": True,
                "total_students": results['total_students'],
                "success_count": results['success_count'],
                "failed_count": results['failed_count'],
                "success_rate": results['success_rate'],
                "report_file": report_file,
                "results": results['results']
            }
            print(json.dumps(batch_result, ensure_ascii=False, indent=2, default=str))

        except Exception as e:
            print(f"‚ö†Ô∏è Kh√¥ng th·ªÉ l∆∞u b√°o c√°o: {e}")
            # In JSON result ngay c·∫£ khi kh√¥ng l∆∞u ƒë∆∞·ª£c file
            batch_result = {
                "success": True,
                "batch_mode": True,
                "total_students": results['total_students'],
                "success_count": results['success_count'],
                "failed_count": results['failed_count'],
                "success_rate": results['success_rate'],
                "results": results['results'],
                "warning": "Kh√¥ng th·ªÉ l∆∞u b√°o c√°o file"
            }
            print(json.dumps(batch_result, ensure_ascii=False, indent=2, default=str))

    else:
        # Default mode - show help
        print("üöÄ FACE FEATURE EXTRACTOR")
        print("=" * 50)
        print("S·ª≠ d·ª•ng:")
        print("  --single-student --student-id <MSSV>  : X·ª≠ l√Ω m·ªôt sinh vi√™n")
        print("  --batch-mode                          : X·ª≠ l√Ω t·∫•t c·∫£ sinh vi√™n")
        print()
        print("V√≠ d·ª•:")
        print("  python face_feature_extractor.py --single-student --student-id 21072006095")
        print("  python face_feature_extractor.py --batch-mode")


if __name__ == "__main__":
    # Ch·∫°y async main v·ªõi argument parsing
    asyncio.run(main())
